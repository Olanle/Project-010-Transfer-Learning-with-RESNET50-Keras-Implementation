{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 009 - Transfer Learning with RESNET50 -  Keras Implementation\n"
      ],
      "metadata": {
        "id": "Yt7vUpYbb4oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, resnet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nLMztaAHktJs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(You can swap this out for your own dataset later.)\n",
        "#Save CIFAR-10 images to folders\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "classes = [\n",
        "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "]\n",
        "\n",
        "def save_split(split_name, images, labels):\n",
        "    base = f\"cifar10_{split_name}\"\n",
        "    os.makedirs(base, exist_ok=True)\n",
        "\n",
        "    for i, (img, lbl) in enumerate(zip(images, labels)):\n",
        "        cls = classes[lbl[0]]\n",
        "        cls_path = os.path.join(base, cls)\n",
        "        os.makedirs(cls_path, exist_ok=True)\n",
        "        cv2.imwrite(os.path.join(cls_path, f\"{i}.png\"), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "save_split(\"train\", x_train, y_train)\n",
        "save_split(\"test\", x_test, y_test)"
      ],
      "metadata": {
        "id": "rNPGi8e5l41K",
        "outputId": "3c79fd26-cf0c-4dcb-977b-5bce2497b859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a generator that automatically resizes to 224×224\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_data = train_gen.flow_from_directory(\n",
        "    \"cifar10_train\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "test_data = test_gen.flow_from_directory(\n",
        "    \"cifar10_test\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2JYUdZgnw-m",
        "outputId": "5325fbc0-4431-4441-b256-93831068d3fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50000 images belonging to 10 classes.\n",
            "Found 10000 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply ResNet50 Preprocessing\n",
        "\n",
        "x_train = resnet50.preprocess_input(x_train)\n",
        "x_test = resnet50.preprocess_input(x_test)"
      ],
      "metadata": {
        "id": "iV_wCWfNn9jY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Pre-trained ResNet50 (without top layer)\n",
        "\n",
        "base_model = ResNet50(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False, #this is to help us change the 1000 classes from ImageNet for us to add our own\n",
        "    input_shape=(224, 224, 3) #this defines the expected input to be feed into the ResNet model\n",
        ")\n",
        "\n",
        "# Freeze base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "6PpuBGL-oR-G",
        "outputId": "ed8e58b4-77fb-4e76-cb8a-1c6a56aff588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Custom Classification Head\n",
        "\n",
        "num_classes = 10   # <---- ADD THIS\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "D6_97MLmobwH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the Model\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "XQmHhvjdoib4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "n9zBUzgq-JVX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the Classification Head Only (Feature Extraction)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=test_data,\n",
        "    epochs=7\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1r0AsXnoo3V",
        "outputId": "24622023-d8e3-4c33-fe97-a3bfe0c6e8f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 108ms/step - accuracy: 0.6227 - loss: 1.1225 - val_accuracy: 0.7709 - val_loss: 0.6419\n",
            "Epoch 2/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 102ms/step - accuracy: 0.7453 - loss: 0.7338 - val_accuracy: 0.8023 - val_loss: 0.5676\n",
            "Epoch 3/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 102ms/step - accuracy: 0.7726 - loss: 0.6600 - val_accuracy: 0.8091 - val_loss: 0.5422\n",
            "Epoch 4/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 101ms/step - accuracy: 0.7779 - loss: 0.6278 - val_accuracy: 0.8088 - val_loss: 0.5524\n",
            "Epoch 5/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 102ms/step - accuracy: 0.7957 - loss: 0.5931 - val_accuracy: 0.8167 - val_loss: 0.5243\n",
            "Epoch 6/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 102ms/step - accuracy: 0.7977 - loss: 0.5860 - val_accuracy: 0.8179 - val_loss: 0.5214\n",
            "Epoch 7/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 102ms/step - accuracy: 0.8083 - loss: 0.5499 - val_accuracy: 0.8245 - val_loss: 0.5105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine-Tune the Deeper ResNet Layers (Optional but increases accuracy)\n",
        "\n",
        "for layer in base_model.layers[-30:]:   # Unfreeze last 30 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=test_data,\n",
        "    epochs=5\n",
        ")\n"
      ],
      "metadata": {
        "id": "wulhr_7Iovlw",
        "outputId": "26124a6f-cfcc-48a5-8784-d13c303310bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 143ms/step - accuracy: 0.7717 - loss: 0.7055 - val_accuracy: 0.8623 - val_loss: 0.4125\n",
            "Epoch 2/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 136ms/step - accuracy: 0.8749 - loss: 0.3650 - val_accuracy: 0.8788 - val_loss: 0.3715\n",
            "Epoch 3/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 137ms/step - accuracy: 0.9160 - loss: 0.2437 - val_accuracy: 0.8890 - val_loss: 0.3689\n",
            "Epoch 4/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 137ms/step - accuracy: 0.9436 - loss: 0.1682 - val_accuracy: 0.8860 - val_loss: 0.3825\n",
            "Epoch 5/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 137ms/step - accuracy: 0.9618 - loss: 0.1172 - val_accuracy: 0.8899 - val_loss: 0.3996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate\n",
        "\n",
        "loss, acc = model.evaluate(x_test_resized, y_test)\n",
        "print(\"Final Test Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "aeg9QdyPo18p",
        "outputId": "1d78d99f-1628-4170-a644-2dfd8c40648a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2795049476.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_resized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final Test Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    670\u001b[0m                 \u001b[0;34m\"Arguments `target` and `output` must have the same shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0;34m\"Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 10)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predict on an External Image"
      ],
      "metadata": {
        "id": "6KUqQMj8pQfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_external(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = resnet50.preprocess_input(img_array)\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    print(\"Predicted Class:\", predicted_class)\n",
        "\n",
        "    plt.imshow(image.load_img(img_path))\n",
        "    plt.title(\"Predicted: \" + str(predicted_class))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "predict_external(\"014.png\")\n"
      ],
      "metadata": {
        "id": "GCe4Tt7UpK3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}